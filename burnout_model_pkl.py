# -*- coding: utf-8 -*-
"""burnout_model.pkl

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VlJcM6kvwPgthcfIum4xuGRO3nt_UqBA
"""

import pandas as pd

df = pd.read_csv("/STUDENT BURNOUT LEVEL PREDICTION (Responses) - Form responses 1.csv")   # use your dataset name
pd.set_option('display.max_rows', None)
print(df)
print(df.info())
print(df.shape)
print(df.describe())
print(df.isnull().sum())
# Drop Name column
df = df.drop("Name", axis=1)

# Encode categorical features
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

for col in ["Study Hours", "Sleep Hours", "Stress"]:
    df[col] = le.fit_transform(df[col])

# Simple burnout scoring system (you can adjust weights)
df["burnout_score"] = (
    df["Study Hours"] * 2 +
    (10 - df["Sleep Hours"]) +   # less sleep â†’ higher burnout
    df["Stress"] * 3 +
    (10 - df["CGPA (Out of 10)"]) +
    (100 - df["Attendance Percentage"]) / 10
)

# Convert burnout_score to classes
def classify(score):
    if score <= df["burnout_score"].quantile(0.33):
        return "Low"
    elif score <= df["burnout_score"].quantile(0.66):
        return "Medium"
    else:
        return "High"

df["burnout_class"] = df["burnout_score"].apply(classify)

print(df.head())
print(df["burnout_class"].value_counts())

#preprocessing the data
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder

# Drop score column (not needed for training)
df = df.drop("burnout_score", axis=1)

# Features and target
X = df.drop("burnout_class", axis=1)
y = df["burnout_class"]

# Encode categorical variables
categorical_cols = ["Study Hours", "Sleep Hours", "Stress"]
X = pd.get_dummies(X, columns=categorical_cols)

# Encode target labels (Low=0, Medium=1, High=2)
le = LabelEncoder()
y = le.fit_transform(y)

# Scale numeric features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-test split (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y distribution:", pd.Series(y).value_counts())

#traing ml model
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# 1. Logistic Regression
log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(X_train, y_train)
y_pred_log = log_reg.predict(X_test)

print("Logistic Regression Results:")
print(classification_report(y_test, y_pred_log))
print(confusion_matrix(y_test, y_pred_log))

# 2. Decision Tree
tree = DecisionTreeClassifier(random_state=42)
tree.fit(X_train, y_train)
y_pred_tree = tree.predict(X_test)

print("\nDecision Tree Results:")
print(classification_report(y_test, y_pred_tree))
print(confusion_matrix(y_test, y_pred_tree))

# 3. Random Forest
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

print("\nRandom Forest Results:")
print(classification_report(y_test, y_pred_rf))
print(confusion_matrix(y_test, y_pred_rf))

#confusion matrix for visualization
import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay

# Plot confusion matrix for Random Forest (best model usually)
ConfusionMatrixDisplay.from_estimator(rf, X_test, y_test, cmap="Blues")
plt.title("Confusion Matrix - Random Forest")
plt.show()

#random forest visualization
import numpy as np

feature_importances = rf.feature_importances_
features = X.columns  # after encoding

# Sort features by importance
indices = np.argsort(feature_importances)[::-1]

plt.figure(figsize=(8,6))
plt.bar(range(len(features)), feature_importances[indices], align="center")
plt.xticks(range(len(features)), features[indices], rotation=45, ha="right")
plt.title("Feature Importance - Random Forest")
plt.tight_layout()
plt.show()

#metrics recap
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Predictions
y_pred = rf.predict(X_test)

# Accuracy
acc = accuracy_score(y_test, y_pred)

# Precision, Recall, F1 (macro = average across Low/Medium/High)
prec = precision_score(y_test, y_pred, average="macro")
rec = recall_score(y_test, y_pred, average="macro")
f1 = f1_score(y_test, y_pred, average="macro")

print("ðŸ“Š Metrics Recap (Random Forest)")
print(f"Accuracy : {acc:.2f}")
print(f"Precision: {prec:.2f}")
print(f"Recall   : {rec:.2f}")
print(f"F1 Score : {f1:.2f}")

#saving the model
import joblib

# Save the trained Random Forest model
joblib.dump(rf, "burnout_model.joblib")

# Save the scaler too (needed for preprocessing later)
joblib.dump(scaler, "scaler.joblib")

print("âœ… Model and scaler saved successfully!")

#downloading the model
from google.colab import files
files.download("burnout_model.joblib")
files.download("scaler.joblib")

# Reload model
loaded_model = joblib.load("burnout_model.joblib")
loaded_scaler = joblib.load("scaler.joblib")

# Example: make a new prediction
sample = X_test[0].reshape(1, -1)  # take one student example
prediction = loaded_model.predict(sample)

print("Predicted burnout class:", le.inverse_transform(prediction)[0])

#frontend

Name Study Hours Sleep Hours    Stress  CGPA (Out of 10)  \
0        Krishma Sri     0-2 hrs    9-10 hrs      High             8.200
1           Hemasri      3-5 hrs     7-8 hrs  Moderate             8.600
2       Madhu mitha      0-2 hrs     7-8 hrs  Moderate             9.300
3           Saradha      0-2 hrs    9-10 hrs      High             8.800
4             Jeeva      0-2 hrs    9-10 hrs       Low             8.200
5            Gukhan      6-9 hrs     7-8 hrs      High             8.033
6            Abinesh     0-2 hrs     7-8 hrs      High             8.480
7            Blessy      0-2 hrs     7-8 hrs      High             7.250
8       Dhanushkaran     0-2 hrs     5-6 hrs  Moderate             8.300
9        HemaPriya       6-9 hrs     7-8 hrs      High             8.080
10     Christo Alan      0-2 hrs     7-8 hrs  Moderate             7.540
11        Imthiyaas      0-2 hrs     5-6 hrs      High             8.250
12          Gowtham      0-2 hrs     5-6 hrs      High             8.570
13          Likethan     0-2 hrs     7-8 hrs      High             8.300
14     Joyce Sruthi      3-5 hrs     7-8 hrs  Moderate             8.430
15       Kokiladevi      0-2 hrs     7-8 hrs  Moderate             8.300
16            Kaviya     3-5 hrs     5-6 hrs       Low             9.000
17         Aiswarya      0-2 hrs     7-8 hrs       Low             8.600
18             Reena     3-5 hrs    9-10 hrs      High             8.000
19           Ramesh      3-5 hrs    9-10 hrs       Low             9.000
20           Dhanam      6-9 hrs    9-10 hrs       Low             9.700
21      Bhavatharani     0-2 hrs     7-8 hrs  Moderate             9.670
22             Yadaw     0-2 hrs     5-6 hrs      High             6.760
23            Swetha     3-5 hrs     7-8 hrs  Moderate             8.800
24  Krishna Prasath      0-2 hrs    9-10 hrs       Low             7.340
25          Semmozhi     3-5 hrs     7-8 hrs      High             8.560
26         Aiswarya      3-5 hrs     7-8 hrs  Moderate             8.600
27     Hari prasath      0-2 hrs     7-8 hrs      High             7.510
28           Harish      3-5 hrs     5-6 hrs       Low             7.500
29           Divakar     0-2 hrs     7-8 hrs  Moderate             8.500

    Attendance Percentage
0                   87.00
1                   95.00
2                   97.70
3                   96.70
4                   97.77
5                   86.36
6                   80.00
7                   93.00
8                   82.00
9                   80.00
10                  75.00
11                  93.00
12                 100.00
13                  80.00
14                 100.00
15                  90.00
16                  97.33
17                  73.33
18                  80.50
19                  95.30
20                  98.30
21                  93.00
22                  51.23
23                  97.20
24                  81.30
25                  97.00
26                  97.76
27                  91.93
28                  95.00
29                  60.00
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 30 entries, 0 to 29
Data columns (total 6 columns):
 #   Column                 Non-Null Count  Dtype
---  ------                 --------------  -----
 0   Name                   30 non-null     object
 1   Study Hours            30 non-null     object
 2   Sleep Hours            30 non-null     object
 3   Stress                 30 non-null     object
 4   CGPA (Out of 10)       30 non-null     float64
 5   Attendance Percentage  30 non-null     float64
dtypes: float64(2), object(4)
memory usage: 1.5+ KB
None
(30, 6)
       CGPA (Out of 10)  Attendance Percentage
count         30.000000              30.000000
mean           8.339100              88.090333
std            0.675697              11.898755
min            6.760000              51.230000
25%            8.044750              80.700000
50%            8.365000              93.000000
75%            8.600000              97.150000
max            9.700000             100.000000
Name                     0
Study Hours              0
Sleep Hours              0
Stress                   0
CGPA (Out of 10)         0
Attendance Percentage    0
dtype: int64
   Study Hours  Sleep Hours  Stress  CGPA (Out of 10)  Attendance Percentage  \
0            0            2       0               8.2                  87.00
1            1            1       2               8.6                  95.00
2            0            1       2               9.3                  97.70
3            0            2       0               8.8                  96.70
4            0            2       1               8.2                  97.77

   burnout_score burnout_class
0         11.100           Low
1         18.900          High
2         15.930        Medium
3          9.530           Low
4         13.023           Low
burnout_class
Low       10
High      10
Medium    10
Name: count, dtype: int64
X_train shape: (24, 11)
X_test shape: (6, 11)
y distribution: 1    10
0    10
2    10
Name: count, dtype: int64
Logistic Regression Results:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00         3
           1       1.00      1.00      1.00         1
           2       1.00      1.00      1.00         2

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

[[3 0 0]
 [0 1 0]
 [0 0 2]]

Decision Tree Results:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00         3
           1       0.50      1.00      0.67         1
           2       1.00      0.50      0.67         2

    accuracy                           0.83         6
   macro avg       0.83      0.83      0.78         6
weighted avg       0.92      0.83      0.83         6

[[3 0 0]
 [0 1 0]
 [0 1 1]]

Random Forest Results:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      1.00      1.00         1
           2       1.00      0.50      0.67         2

    accuracy                           0.83         6
   macro avg       0.92      0.83      0.84         6
weighted avg       0.88      0.83      0.82         6

[[3 0 0]
 [0 1 0]
 [1 0 1]]

ðŸ“Š Metrics Recap (Random Forest)
Accuracy : 0.83
Precision: 0.92
Recall   : 0.83
F1 Score : 0.84
âœ… Model and scaler saved successfully!

Predicted burnout class: Low

